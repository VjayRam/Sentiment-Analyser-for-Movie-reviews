{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b770b0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import nltk\n",
    "from nltk import NaiveBayesClassifier\n",
    "from nltk.corpus import movie_reviews\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62bea271",
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = movie_reviews.categories()\n",
    "reviews = []\n",
    "for cat in cats:\n",
    "    for fid in movie_reviews.fileids(cat):\n",
    "        review = (list(movie_reviews.words(fid)),cat)\n",
    "        reviews.append(review)\n",
    "random.shuffle(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6b0aa02",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_wd_in_reviews = nltk.FreqDist(wd.lower() for wd in movie_reviews.words())\n",
    "top_wd_in_reviews = [list(wds) for wds in zip(*all_wd_in_reviews.most_common(2000))][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c4eaefed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ext_ft(review,top_words):\n",
    "    review_wds = set(review)\n",
    "    ft = {}\n",
    "    for wd in top_words:\n",
    "        ft['word_present({})'.format(wd)] = (wd in review_wds)\n",
    "    return ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6334f631",
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(ext_ft(d,top_wd_in_reviews), c) for (d,c) in reviews]\n",
    "train_set, test_set = featuresets[200:], featuresets[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "52a678bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.84\n"
     ]
    }
   ],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "afd033b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "word_present(outstanding) = True              pos : neg    =     10.2 : 1.0\n",
      "    word_present(seagal) = True              neg : pos    =      7.1 : 1.0\n",
      "     word_present(mulan) = True              pos : neg    =      6.9 : 1.0\n",
      "word_present(wonderfully) = True              pos : neg    =      6.7 : 1.0\n",
      "    word_present(poorly) = True              neg : pos    =      5.7 : 1.0\n",
      "     word_present(flynt) = True              pos : neg    =      5.6 : 1.0\n",
      "      word_present(lame) = True              neg : pos    =      5.5 : 1.0\n",
      "    word_present(wasted) = True              neg : pos    =      5.4 : 1.0\n",
      "     word_present(damon) = True              pos : neg    =      5.2 : 1.0\n",
      "word_present(ridiculous) = True              neg : pos    =      5.2 : 1.0\n",
      "     word_present(awful) = True              neg : pos    =      5.1 : 1.0\n",
      "     word_present(waste) = True              neg : pos    =      5.0 : 1.0\n",
      "     word_present(worst) = True              neg : pos    =      4.7 : 1.0\n",
      "   word_present(unfunny) = True              neg : pos    =      4.6 : 1.0\n",
      "      word_present(dull) = True              neg : pos    =      4.5 : 1.0\n",
      "       word_present(era) = True              pos : neg    =      4.3 : 1.0\n",
      " word_present(laughable) = True              neg : pos    =      4.3 : 1.0\n",
      "      word_present(mess) = True              neg : pos    =      4.2 : 1.0\n",
      " word_present(portrayal) = True              pos : neg    =      4.1 : 1.0\n",
      " word_present(fantastic) = True              pos : neg    =      4.1 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e21ef80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_vectorizer=None\n",
    "def get_train_test(train_set,test_set):\n",
    "    global dict_vectorizer\n",
    "    dict_vectorizer = DictVectorizer(sparse=False)\n",
    "    X_train, y_train = zip(*train_set)\n",
    "    X_train = dict_vectorizer.fit_transform(X_train)\n",
    "    X_test,y_test = zip(*test_set)\n",
    "    X_test = dict_vectorizer.transform(X_test)\n",
    "    return X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0be2941a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_jobs=4, random_state=10)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = get_train_test(train_set,test_set)\n",
    "rf = RandomForestClassifier(n_estimators=100,n_jobs=4,random_state=10)\n",
    "rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0fb35f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.795\n"
     ]
    }
   ],
   "source": [
    "preds = rf.predict(X_test)\n",
    "print(accuracy_score(y_test,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "47422c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords_list = stopwords.words('english')\n",
    "all_words_in_reviews = nltk.FreqDist(word.lower() for word in movie_reviews.words() if word not in stopwords_list)\n",
    "top_words_in_reviews = [list(words) for words in zip(*all_words_in_reviews.most_common(2000))][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a01d15bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(ext_ft(d,top_words_in_reviews), c) for (d,c) in reviews]\n",
    "train_set, test_set = featuresets[200:], featuresets[:200]\n",
    "X_train,X_test,y_train,y_test = get_train_test(train_set,test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8dfcfca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_jobs=4, random_state=10)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100,n_jobs=4,random_state=10)\n",
    "rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "77bc0ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.78\n"
     ]
    }
   ],
   "source": [
    "preds = rf.predict(X_test)\n",
    "print(accuracy_score(y_test,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5f5a6d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('word_present(bad)', 0.016739520639103028), ('word_present(mess)', 0.006629632281019339), ('word_present(stupid)', 0.006534607470282351), ('word_present(worst)', 0.006487818472443368), ('word_present(boring)', 0.005631611763307368), ('word_present(lame)', 0.005081177157544614), ('word_present(waste)', 0.004954570648885522), ('word_present(wasted)', 0.004256251522246547), ('word_present(awful)', 0.004213821004719616), ('word_present(dull)', 0.004163115309051399), ('word_present(supposed)', 0.004126325952489547), ('word_present(outstanding)', 0.0040604778013627486), ('word_present(ridiculous)', 0.0038293804751775074), ('word_present(excellent)', 0.0037160673869480604), ('word_present(memorable)', 0.003542931435602152), ('word_present(also)', 0.0033486414991687388), ('word_present(perfectly)', 0.0033066324754177324), ('word_present(life)', 0.0030930714572762635), ('word_present(best)', 0.0030499798779878517), ('word_present(plot)', 0.003039673355764874)]\n"
     ]
    }
   ],
   "source": [
    "features_list = zip(dict_vectorizer.get_feature_names(),rf.feature_importances_)\n",
    "features_list = sorted(features_list, key=lambda x: x[1], reverse=True)\n",
    "print(features_list[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff2f49b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
